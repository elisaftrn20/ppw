
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Crawling Data &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Crawling';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Pengantar Web Mining" href="Tugas.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="Profile.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/Profile (1).jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/Profile (1).jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="Profile.html">
                    Profile
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Tugas.html">Pengantar Web Mining</a></li>














<li class="toctree-l1 current active"><a class="current reference internal" href="#">Crawling Data</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FCrawling.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Crawling.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling Data</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-library-sprynger">1. Install Library Sprynger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-api-key">2. Menyiapkan API Key</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#script-crawling-python">3. Script Crawling Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-keyword-web-mining">A. Keyword Web Mining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-keyword-web-usage-mining">B. Keyword Web Usage Mining</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="crawling-data">
<h1>Crawling Data<a class="headerlink" href="#crawling-data" title="Link to this heading">#</a></h1>
<p>Proses untuk Crawling data yaitu,</p>
<section id="install-library-sprynger">
<h2>1. Install Library Sprynger<a class="headerlink" href="#install-library-sprynger" title="Link to this heading">#</a></h2>
<p>Untuk memasang library Python resmi Springer Nature, jalankan:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>sprynger
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting sprynger
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading sprynger-0.4.1-py3-none-any.whl.metadata (5.8 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting lxml (from sprynger)
  Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)
Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.32.4)
Requirement already satisfied: urllib3 in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (2.5.0)
Requirement already satisfied: platformdirs in /home/codespace/.local/lib/python3.12/site-packages (from sprynger) (4.3.8)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: charset_normalizer&lt;4,&gt;=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (3.4.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (3.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests-&gt;sprynger) (2025.7.9)
Downloading sprynger-0.4.1-py3-none-any.whl (40 kB)
Downloading lxml-6.0.1-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
?25l   <span class=" -Color -Color-C237">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">0.0/5.3 MB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   <span class=" -Color -Color-Red">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">5.3/5.3 MB</span> <span class=" -Color -Color-Red">51.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25h
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: lxml, sprynger
?25l
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   <span class=" -Color -Color-C237">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">0/2</span> [lxml]
   <span class=" -Color -Color-Red">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Green">2/2</span> [sprynger]
?25h

</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully installed lxml-6.0.1 sprynger-0.4.1

<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> A new release of pip is available: <span class=" -Color -Color-Red">25.1.1</span> -&gt; <span class=" -Color -Color-Green">25.2</span>
<span class=" -Color -Color-Bold">[</span><span class=" -Color -Color-Blue">notice</span><span class=" -Color -Color-Bold">]</span> To update, run: <span class=" -Color -Color-Green">python3 -m pip install --upgrade pip</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="menyiapkan-api-key">
<h2>2. Menyiapkan API Key<a class="headerlink" href="#menyiapkan-api-key" title="Link to this heading">#</a></h2>
<p>Setiap pencarian membutuhkan API Key dari Springer Nature agar kita diizinkan mengambil data.
Daftar di Springer Nature Developer di <a class="reference external" href="https://dev.springernature.com/#api">https://dev.springernature.com/#api</a></p>
</section>
<section id="script-crawling-python">
<h2>3. Script Crawling Python<a class="headerlink" href="#script-crawling-python" title="Link to this heading">#</a></h2>
<p>Setelah mendapatkan api key dari Springer Nature Developer, masukkan API yang telah didapat ke dalam code dibawah ini, dan saya mengimplementasikannya dengan menggunakan keyword web mining dan web usage mining</p>
<section id="a-keyword-web-mining">
<h3>A. Keyword Web Mining<a class="headerlink" href="#a-keyword-web-mining" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># API Key Meta API</span>
<span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;00e6e834d8efc1827d4b56d5091e03b1&quot;</span>
<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;web mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;keyword:&quot;</span><span class="si">{</span><span class="n">keyword</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>  <span class="c1"># jumlah hasil per request</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># List untuk menyimpan semua record</span>
<span class="n">all_records</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="n">total_results</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;total&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">total_results</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;records&quot;</span><span class="p">,</span> <span class="p">[]):</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Simpan record ke list</span>
        <span class="n">all_records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;keyword&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
            <span class="s2">&quot;doi&quot;</span><span class="p">:</span> <span class="n">doi</span><span class="p">,</span>
            <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
            <span class="s2">&quot;abstract&quot;</span><span class="p">:</span> <span class="n">abstract</span>
        <span class="p">})</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Simpan ke CSV</span>
<span class="k">if</span> <span class="n">all_records</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_records</span><span class="p">)</span>
    <span class="n">csv_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">keyword</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">.csv&quot;</span>  <span class="c1"># keyword_web_mining.csv</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_filename</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 437

DOI: 10.1007/s41060-023-00483-9
Title: Artificial intelligence trend analysis in German business and politics: a web mining approach
Abstract: Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.

DOI: 10.1007/s11135-024-01978-8
Title: Information diffusion in referral networks: an empirical investigation of the crypto asset landscape
Abstract: In the last decades, crypto assets have become particularly popular in financial markets. However, public awareness of the crypto asset landscape is rather limited, and usually associated with sensationalized media coverage of a handful of cryptocurrencies. Moreover, while users of crypto assets primarily collect information on Internet, there is a limited understanding of the relational (online) structures supporting the diffusion of information about these financial products. Therefore, the aim of this study is to uncover the structure of online information referral networks dedicated to crypto assets. By adopting a multi-method approach consisting of web scraping, web analytics, and social network analysis, we use data from the top 200 crypto assets by market capitalization to identify pivotal websites and the overall connectedness of the information referral networks. Our results show that social media and news channel sites play a key role in the information diffusion process, while market and trading sites signal innovation adoption. Overall, cryptocurrencies’ websites do not seem key in the referral network, as opposed to social media websites which, however, cannot be considered mature hubs because of their low connectivity.

DOI: 10.1007/978-3-031-73699-5_16
Title: NoCrypto: A Web Mining Behavior Detection Method Based on RGB Images
Abstract: In recent years, there has been a growing prevalence of mining web pages using the new web technology of WebAssembly (WASM), resulting in the unauthorized exploitation of user resources. However, existing detection methods have shown limited ability to counter obfuscation techniques and have exhibited low detection efficiency. To address these issues, this paper proposes a novel static detection method based on the visualization of WASM modules. The proposed method involves instantiating the binary files of the WASM mining operations within web pages. These binary files are then combined with the information of local entropy and global entropy, resulting in the visualization of RGB images. Compared to grayscale images, RGB images retain more of the original file information. After training and learning the image features using a convolutional neural network (CNN), the model achieves an impressive accuracy rate of 99.18% when tested on real-world web pages. This accuracy is approximately 2% higher than that of existing visualization-based detection methods. Moreover, the model exhibits a shorter execution time. The proposed NoCrypto method demonstrates quick execution speed and accurate detection.

DOI: 10.1007/978-3-031-85386-9_9
Title: On Understanding the Dark Web Through Graph Analytics
Abstract: The Dark Web, a protected digital graph, contains a wealth of hidden information that evades traditional search engines. This work delves into the mysterious landscape of the Dark Web by analyzing its structure using graph data from a Dark Web crawler. Using exploratory data analysis techniques, we uncover structure, trends, and insights that contribute to a deeper understanding of the content hidden in this dark digital world. This research is a critical step toward understanding the contents of the Dark Web and improving our ability to navigate the complexities of the digital underworld.

DOI: 10.1007/978-3-031-86302-8_5
Title: A Survey on Various Sentiment Analysis Applications Employing Opinion Mining
Abstract: Opinion mining aka sentiment analysis refers to the use of natural language processing, text analysis and computational linguistics to identify and extract subjective information in source data. This, further helps to extract the subjective information into various categories that help in a decision-making process. In this survey, a novel attempt is made to provide an application-specific classification on opinion mining and sentiment analysis. The survey presented here widely covers the processes, levels and challenges of opinion mining that would help the application designers of opinion mining applications.

DOI: 10.1007/978-3-031-81261-3_9
Title: Pillar 3: Did COVID-19 and the War in Ukraine Affect Interest in Mandatory Disclosure?
Abstract: The 2008–2009 financial crisis exposed significant flaws in the Basel II regulatory framework, which was designed to ensure the stability of banking institutions during crises. This economic turmoil led to a loss of confidence in financial systems, liquidity shortages, and a deepening debt crisis across Europe. In response, regulatory standards were reformed, resulting in the development of the Basel III framework, which built upon three pillars. Pillar 1 introduced better capital forms, higher capital ratios, and capital reserves. Pillar 2 increased risk management requirements and emphasized the supervisory authorities’ responsibilities. Pillar 3 enhanced the scope and detail of published information, aiming to improve market discipline and stakeholder understanding of banks’ risks and capital positions. Our study analyzes how crisis periods affected interest in Pillar 3 disclosures, examining changes in interest from 2016 to 2022 using data from a specific bank’s log files. The results, performed through association analysis, indicate a significant decrease in interest in mandatory disclosures during the periods of the COVID-19 pandemic as well as the energy crisis and the war in Ukraine.

DOI: 10.1007/978-3-031-81596-6_14
Title: A Review of the Challenges with Massive Web-Mined Corpora Used in Large Language Models Pre-training
Abstract: This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain, including challenges such as noise (irrelevant or misleading information), duplication of content, the presence of low-quality or incorrect information, biases, and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate, reliable, and ethically responsible language models. Through an examination of current methodologies for data cleaning, pre-processing, bias detection and mitigation, we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.

DOI: 10.1007/s41060-024-00695-7
Title: Mapping sustainable development goals to citizen science projects–a comparative evaluation of automatic classifiers
Abstract: Traditional data sources provide insufficient knowledge for measuring the United Nations Sustainable Development Goals (SDGs). Data related to SDGs are sourced primarily from global databases maintained by international organizations, national statistical offices and other government agencies. Recent studies show the value of using data from Citizen Science (CS) for assessing the SDGs. There is an important online presence of CS programs, professional networks for CS and online communities of citizen scientists, leading to the generation of several CS platforms. In this context, the role of computational data science is key. This paper explores and exemplifies opportunities for combining web-data mining techniques and automatic classifiers to enhance the understanding of the inter-relation between CS and the SDGs. An analysis of different automatic classifiers is presented by comparing the results obtained from their application in a sample of 208 CS project descriptions. The results of this study indicate the benefits and limitations of these techniques (nCoder, ESA, OSDG and BERT), but also provides a discussion of the potential benefits of using data from CS projects to map the 17 SDGs.

DOI: 10.1007/s10899-024-10337-z
Title: Illegal Online Gambling Site Detection using Multiple Resource-Oriented Machine Learning
Abstract: The COVID-19 pandemic has led to faster digitalization and illegal online gambling has become popular. As illegal online gambling brings not only financial threats but also breaches in overall cyber security, this study defines the concept of absolute illegal online gambling (AIOG) using a machine-learning-driven approach with information gathered from public webpages. By analysing 11,172 sites to detect illegal online gambling, the proposed model classifies key features such as URLs (Uniform Resource Locator), WHOIS, INDEX, and landing page information. With a combination of text and image analyses with machine learning-driven approach, the proposed model offers the ensemble combination of attributes for high detection performance with the verification of common attributes from metadata in online gambling. This study suggests a strategy for dynamic resource utilization to increase the classification accuracy of the current environment. As a result, this research expands the scope of hybrid web mining through constant updating of data to achieve content-based filtering.

DOI: 10.1007/s13132-023-01587-0
Title: Measuring Innovation in Mauritius’ ICT Sector
            Using Unsupervised Machine Learning: A Web Mining and Topic Modeling
            Approach
Abstract: Measuring innovation accurately and efficiently is crucial for policymakers to encourage innovation activity. However, the established indicator landscape lacks timeliness and accuracy. In this study, we focus on the country of Mauritius that is transforming its economy towards the information and communication technology (ICT) sector. We seek to extend the knowledge base on innovation activity and the status quo of innovation in Mauritius by applying an unsupervised machine learning approach. Building on previous work on new experimental innovation indicators, we combine recent advances in web mining and topic modeling and address the following research questions: What are potential areas of innovation activity in the ICT sector of Mauritius? Furthermore, do web mining and topic modeling provide sufficient indicators to understand innovation activities in emerging countries? To answer these questions, we apply the natural language processing (NLP) technique of Latent Dirichlet Allocation (LDA) to ICT companies’ website text data. We then generate topic models from the scraped text data. As a result, we derive seven categories that describe the innovation activities of ICT firms in Mauritius. Albeit the model approach fulfills the requirements for innovation indicators as suggested in the Oslo Manual, it needs to be combined with additional metrics for innovation, for example, with traditional indicators such as patents, to unfold its potential. Furthermore, our approach carries methodological implications and is intended to be reproduced in similar contexts of scarce or unavailable data or where traditional metrics have demonstrated insufficient explanatory power.
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-keyword-web-usage-mining">
<h3>B. Keyword Web Usage Mining<a class="headerlink" href="#b-keyword-web-usage-mining" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># API Key Meta API</span>
<span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;00e6e834d8efc1827d4b56d5091e03b1&quot;</span>
<span class="n">keyword</span> <span class="o">=</span> <span class="s2">&quot;web usage mining&quot;</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://api.springernature.com/meta/v2/json&quot;</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;q&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;keyword:&quot;</span><span class="si">{</span><span class="n">keyword</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">,</span>
    <span class="s2">&quot;api_key&quot;</span><span class="p">:</span> <span class="n">api_key</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">10</span>  <span class="c1"># jumlah hasil per request</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># List untuk menyimpan semua record</span>
<span class="n">all_records</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
    <span class="n">total_results</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;result&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;total&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total hasil: </span><span class="si">{</span><span class="n">total_results</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">record</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;records&quot;</span><span class="p">,</span> <span class="p">[]):</span>
        <span class="n">doi</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;doi&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;No title&#39;</span><span class="p">)</span>
        <span class="n">abstract</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;abstract&#39;</span><span class="p">,</span> <span class="s1">&#39;No abstract&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DOI: </span><span class="si">{</span><span class="n">doi</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Title: </span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Abstract: </span><span class="si">{</span><span class="n">abstract</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Simpan record ke list</span>
        <span class="n">all_records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;keyword&quot;</span><span class="p">:</span> <span class="n">keyword</span><span class="p">,</span>
            <span class="s2">&quot;doi&quot;</span><span class="p">:</span> <span class="n">doi</span><span class="p">,</span>
            <span class="s2">&quot;title&quot;</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
            <span class="s2">&quot;abstract&quot;</span><span class="p">:</span> <span class="n">abstract</span>
        <span class="p">})</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Simpan ke CSV</span>
<span class="k">if</span> <span class="n">all_records</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_records</span><span class="p">)</span>
    <span class="n">csv_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">keyword</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">.csv&quot;</span>  <span class="c1"># keyword_web_mining.csv</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">csv_filename</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✅ Data berhasil disimpan ke </span><span class="si">{</span><span class="n">csv_filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total hasil: 198

DOI: 10.1007/978-981-96-0476-0_15
Title: The “Server Access Pattern Analysis” Based on Different “Weblogs Classification” Methods
Abstract: The academic and industrial sectors have shown a significant increase in interest in web usage mining due to its potential for applications. This work offers a thorough taxonomy of the work being done in this subject, including research projects and the way people use the internet today. During the functioning of the system, extensive information and runtime statistics are recorded in the logs. It includes a log message along with a timestamp that indicates what has taken place in the system. A recent review of the work that has previously performed is also presented, considering various data mining methodologies including clustering and classification. The primary focus of this study is the data preprocessing step, which includes activities such as data cleansing techniques and field extraction at the preliminary stage of ‘web usage mining’. ‘The procedure of ‘extracting’ fields from the log file’s single line is carried out by the field extraction algorithm’. The evaluated data is cleaned by an algorithm that removes items that are incorrect or unnecessary.

DOI: 10.1007/978-981-97-9855-1_33
Title: Analyze User Navigational Patterns from Log Data Using Hadoop Techniques
Abstract: Web usage mining is the process of extracting useful information from web server logs, user interactions, and other web data in order to understand and optimize how users interact with a website. This technique involves analyzing data generated by user activities to discover patterns, trends, and insights that can inform various business and technical decisions. In this research article, we use the Hadoop technique to analyze the behavior of user navigation patterns from log data. This method helps to understand how users interact with websites. For instance, we track the quantity of user logins, the quantity of item sets, the frequency of item sets’ searches, and determine the execution time of various web usage mining algorithms across varying support counts. This article proposes a joint SPM-a priori web mining technique that uses semantic information to improve the generation of frequent sequences and reduces execution time for different support counts. We com-pared existing a priori, web log search, and modified web log search with the proposed join SPM a priori algorithm in Sci-Hub, Pubg game log, Amazon e-commerce, and cryptocurrency datasets. We also found out how long each one took to run for different support counts. The results section says that the proposed SPM-a priori algorithm runs faster than all other algorithms. This means that the proposed system is better for analyzing execution time for user navigational pattern analysis.

DOI: 10.1007/s00799-024-00397-2
Title: Robots still outnumber humans in web archives in 2019, but less than in 2015 and 2012
Abstract: The significance of the web and the crucial role of web archives in its preservation highlight the necessity of understanding how users, both human and robot, access web archive content, and how best to satisfy this disparate needs of both types of users. To identify robots and humans in web archives and analyze their respective access patterns, we used the Internet Archive’s (IA) Wayback Machine access logs from 2012, 2015, and 2019, as well as Arquivo.pt’s (Portuguese Web Archive) access logs from 2019. We identified user sessions in the access logs and classified those sessions as human or robot based on their browsing behavior. To better understand how users navigate through the web archives, we evaluated these sessions to discover user access patterns. Based on the two archives and between the three years of IA access logs (2012 vs. 2015 vs. 2019), we present a comparison of detected robots vs. humans and their user access patterns and temporal preferences. The total number of robots detected in IA 2012 (91% of requests) and IA 2015 (88% of requests) is greater than in IA 2019 (70% of requests). Robots account for 98% of requests in Arquivo.pt (2019). We found that the robots are almost entirely limited to “Dip” and “Skim” access patterns in IA 2012 and 2015, but exhibit all the patterns and their combinations in IA 2019. Both humans and robots show a preference for web pages archived in the near past.

DOI: 10.1007/978-981-99-8646-0_16
Title: Server Access Pattern Analysis Based on Weblogs Classification Methods
Abstract: The world of today relies heavily on the internet, online pages, and applications in their daily lives. Web usage mining uses data-mining approaches to extract use patterns from web data in sequence to better comprehend and satisfy Requirements for web-based applications web-based applications. The three phases of web usage mining are pattern identification, pattern analysis, and preprocessing. In-depth explanations of pattern and prediction analysis based on web usage mining are provided in this work. Due to its potential for applications, web usage mining has seen a substantial increase in interest from the academic and industrial sectors. The work in this topic, including research projects and current web usage patterns, is thoroughly taxonomized in this book. Many details and runtime data are captured in logs as the system is operating. A timestamp and a log message that describe what happened in the system are included. The work that has already been done is also reviewed recently, taking into account different data mining approaches including clustering and classification.

DOI: 10.1007/978-981-97-5227-0_31
Title: Prediction and Analysis of Next Website Requests: A Hybrid Approach Integrating Fuzzy Clustering and Fuzzy Association Rule Mining
Abstract: Data mining is a vital process for extracting valuable knowledge and intriguing patterns from existing databases, tailored for specific objectives. In the context of web usage mining, the increasing intricacies of web usage necessitate the development of more efficient techniques to predict user behaviour and enhance website performance. Traditional clustering approach ensures that related data points are grouped together while segregating unrelated ones. This study introduces the fuzzy clustering method, which involves categorizing a set of data points into multiple clusters. Fuzzy clustering is employed, allowing data points to possess varying degrees of membership in multiple clusters. Traditional data mining algorithms predominantly rely on binary values to identify transaction relationships. However, real-world applications frequently involve transactions with quantitative values, presenting a substantial challenge in algorithm design. Study presents a pioneering approach that leverages fuzzy clustering algorithms to predict the next website request made by users with a degree of uncertainty and vagueness. This integration of fuzziness results in more precise predictions of user behaviour. Methodologically, study enhances the conventional clustering and association rule mining method by incorporating fuzzy clustering base fuzzy association rule mining method. Paper presents a novel architecture based on fuzzy clustering client based on interest for fuzzy predictions, effectively addressing these challenges.

DOI: 10.1007/s00500-023-08019-w
Title: IRPDP_HT2: a scalable data pre-processing method in web usage mining using Hadoop MapReduce
Abstract: Data preparation is a vital step in the web usage mining process since it provides structured data for the subsequent stages. Hence, it is necessary to convert raw server logs into user sessions to generate structured data for pattern discovery phase. In recent decade, popular websites’ server log production has risen to many terabytes to petabytes each day. As a result, server logs possess big data issues such as storage and processing. This study focuses on initial phases of web usage mining process such as data cleaning, user identification, and session identification. These phases are classified as data-intensive processes and deemed-computation intensive. In the last decade, MapReduce emerges as one of the best parallel programming frameworks for data-intensive applications. An efficient MapReduce-based data pre-processing algorithm, i.e. IRPDP_HT2, is proposed in this study. Previous parallel data pre-processing algorithms either include partial phases or lack with efficient robot detection approaches. IRPDP_HT2 algorithm uses a variety of efficient heuristics in all three phases of data pre-processing to identify both ethical and unethical robots. The suggested IRPDP_HT2 approach is found to be effective and scalable for larger datasets after various experiments on a cluster of nodes. The effectiveness of suggested heuristics is also examined during session identification phase. Three variants of IRPDP_HT2 such as PDP_HT2, IPDP_HT2, and RPDP_HT2 are also developed and tested. Impact of robots’ requests and internal dummy connections’ requests on session count by IRPDP_HT2 algorithm is 45.81% which is more than in PDP_HT2, IPDP_HT2, and RPDP_HT2 algorithms. Further speed-up and size-up are also analysed to demonstrate scalability of algorithm. In the presence of larger datasets, the algorithm’s running time falls, while the number of data nodes grows. The size-up of IRPDP_HT2 demonstrates that even after doubling the input data, the algorithm’s running time does not grow in that ratio for the fixed number of data nodes.

DOI: 10.1007/978-981-99-4284-8_3
Title: Multi-criteria-Based Page Ranking Using Metaheuristic Swarm Optimization
Abstract: The size of data on the internet has grown enormously and also growing continuously. Finding any information for a user in response to query has become a challenging task. In this, search engines are playing a vital role. Yet, these are unable to a retrieve the relevant information. These search engines use some limited criteria to fetch the results in response to the user&#39;s query after ranking and indexing the pages. In this paper, a multi-criteria-based approach has been proposed to rank web pages. These criteria include keywords, user access count, unique visitors, stay time, hubs, and authority values. The proposed approach uses particle swarm optimization to find the optimal results. And, this algorithm has been compared with some existing algorithms based on iterative improvement and genetic algorithm. It has been observed that the proposed approach is able to find the most relevant top-ranked pages.

DOI: 10.1007/978-3-031-29078-7_60
Title: Website Personalization Using Association Rules Mining
Abstract: Many companies are redefining their business strategies to improve the business output. Business over internet provides the opportunity to customers and partners where their products and specific business can be found. Web usage mining is the type of web mining activity that involves the automatic discovery of user access patterns from web servers. A real-world challenging task of the web master of an organization is to match the needs of user and keep their attention in their web site. So, web pages can capture the intuition of the user and provide them with the recommendation list. Personalize e-commerce website is done after knowing the habits and behavior patterns of customers e-commerce website using web usage mining with association rules mining apriori algorithms. The method used is a method of analysis and design. In the method of analysis, research variables are determined, and data of sales are collected. In addition, the method of analysis is also performed to measure the accuracy of the apriori algorithm. Designing apriori, program design, and the design of the screen is done in the design method. Results are achieved in the form of an e-commerce website that is personalized using association rules mining apriori algorithm that can recommend the goods in accordance with the preferences and needs of the user. The conclusion of this study is to obtain patterns of association, it takes the data transactions made by customers and the recommendations given by the apriori algorithm would be more accurate if the transaction data is processed more, the categories of goods are fewer, the limit minimum value of support and the limit minimum value of confidence are high.

DOI: 10.1007/978-981-99-7969-1_7
Title: Web Usage Mining for Determining a Website’s Usage Pattern: A Case Study of Government Website
Abstract: Web usage mining is a crucial research area that aims to uncover user behavior patterns from web log data because web usage mining can be used to analyze a website’s usage. This study examined web usage mining to discover online users’ usage patterns and used the results to redesign and improve the government website. This study aims to help online customers obtain a better experience. A dataset was collected from the Metropolitan Electricity Authority (MEA) website. Various algorithms, including association rule mining (Apriori and Frequent Pattern-Growth (FP-Growth)) and sequential pattern mining (Generalized Sequential Pattern (GSP) and Prefix-Span), were used to mine the user usage data. The first 30 frequently visited patterns of web usage mining results were selected for analysis and to develop a prototype. It revealed that most pages were accessed directly. Moreover, most users were interested in alternative energy information, the Fuel Adjustment Charge (at the given time) or the FT rate, the power outage announcement page, and reducing electric expenses information. Furthermore, the analysis indicated that customers were interested in making online processes, such as using the contact-us feature, downloading forms, and calculating their electric expenses. A survey was conducted with 30 participants and the results were compared with the usage data from the weblog. Welch’s t-test was utilized to evaluate the prototype. The findings indicated that the newly implemented website, based on the user usage patterns, was more effective and reduced the user’s usage time.

DOI: 10.1007/978-3-031-16802-4_19
Title: Robots Still Outnumber Humans in Web Archives, But Less Than Before
Abstract: To identify robots and humans and analyze their respective access patterns, we used the Internet Archive’s (IA) Wayback Machine access logs from 2012 and 2019, as well as Arquivo.pt’s (Portuguese Web Archive) access logs from 2019. We identified user sessions in the access logs and classified those sessions as human or robot based on their browsing behavior. To better understand how users navigate through the web archives, we evaluated these sessions to discover user access patterns. Based on the two archives and between the two years of IA access logs (2012 vs. 2019), we present a comparison of detected robots vs. humans and their user access patterns and temporal preferences. The total number of robots detected in IA 2012 is greater than in IA 2019 (21% more in requests and 18% more in sessions). Robots account for 98% of requests (97% of sessions) in Arquivo.pt (2019). We found that the robots are almost entirely limited to “Dip” and “Skim” access patterns in IA 2012, but exhibit all the patterns and their combinations in IA 2019. Both humans and robots show a preference for web pages archived in the near past.


✅ Data berhasil disimpan ke web_usage_mining.csv
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;web_mining.csv&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| keyword    | doi                          | title                                                                                                               | abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|:-----------|:-----------------------------|:--------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| web mining | 10.1007/s41060-023-00483-9   | Artificial intelligence trend analysis in German business and politics: a web mining approach                       | Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| web mining | 10.1007/s11135-024-01978-8   | Information diffusion in referral networks: an empirical investigation of the crypto asset landscape                | In the last decades, crypto assets have become particularly popular in financial markets. However, public awareness of the crypto asset landscape is rather limited, and usually associated with sensationalized media coverage of a handful of cryptocurrencies. Moreover, while users of crypto assets primarily collect information on Internet, there is a limited understanding of the relational (online) structures supporting the diffusion of information about these financial products. Therefore, the aim of this study is to uncover the structure of online information referral networks dedicated to crypto assets. By adopting a multi-method approach consisting of web scraping, web analytics, and social network analysis, we use data from the top 200 crypto assets by market capitalization to identify pivotal websites and the overall connectedness of the information referral networks. Our results show that social media and news channel sites play a key role in the information diffusion process, while market and trading sites signal innovation adoption. Overall, cryptocurrencies’ websites do not seem key in the referral network, as opposed to social media websites which, however, cannot be considered mature hubs because of their low connectivity.                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| web mining | 10.1007/978-3-031-73699-5_16 | NoCrypto: A Web Mining Behavior Detection Method Based on RGB Images                                                | In recent years, there has been a growing prevalence of mining web pages using the new web technology of WebAssembly (WASM), resulting in the unauthorized exploitation of user resources. However, existing detection methods have shown limited ability to counter obfuscation techniques and have exhibited low detection efficiency. To address these issues, this paper proposes a novel static detection method based on the visualization of WASM modules. The proposed method involves instantiating the binary files of the WASM mining operations within web pages. These binary files are then combined with the information of local entropy and global entropy, resulting in the visualization of RGB images. Compared to grayscale images, RGB images retain more of the original file information. After training and learning the image features using a convolutional neural network (CNN), the model achieves an impressive accuracy rate of 99.18% when tested on real-world web pages. This accuracy is approximately 2% higher than that of existing visualization-based detection methods. Moreover, the model exhibits a shorter execution time. The proposed NoCrypto method demonstrates quick execution speed and accurate detection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| web mining | 10.1007/978-3-031-85386-9_9  | On Understanding the Dark Web Through Graph Analytics                                                               | The Dark Web, a protected digital graph, contains a wealth of hidden information that evades traditional search engines. This work delves into the mysterious landscape of the Dark Web by analyzing its structure using graph data from a Dark Web crawler. Using exploratory data analysis techniques, we uncover structure, trends, and insights that contribute to a deeper understanding of the content hidden in this dark digital world. This research is a critical step toward understanding the contents of the Dark Web and improving our ability to navigate the complexities of the digital underworld.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| web mining | 10.1007/978-3-031-86302-8_5  | A Survey on Various Sentiment Analysis Applications Employing Opinion Mining                                        | Opinion mining aka sentiment analysis refers to the use of natural language processing, text analysis and computational linguistics to identify and extract subjective information in source data. This, further helps to extract the subjective information into various categories that help in a decision-making process. In this survey, a novel attempt is made to provide an application-specific classification on opinion mining and sentiment analysis. The survey presented here widely covers the processes, levels and challenges of opinion mining that would help the application designers of opinion mining applications.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| web mining | 10.1007/978-3-031-81261-3_9  | Pillar 3: Did COVID-19 and the War in Ukraine Affect Interest in Mandatory Disclosure?                              | The 2008–2009 financial crisis exposed significant flaws in the Basel II regulatory framework, which was designed to ensure the stability of banking institutions during crises. This economic turmoil led to a loss of confidence in financial systems, liquidity shortages, and a deepening debt crisis across Europe. In response, regulatory standards were reformed, resulting in the development of the Basel III framework, which built upon three pillars. Pillar 1 introduced better capital forms, higher capital ratios, and capital reserves. Pillar 2 increased risk management requirements and emphasized the supervisory authorities’ responsibilities. Pillar 3 enhanced the scope and detail of published information, aiming to improve market discipline and stakeholder understanding of banks’ risks and capital positions. Our study analyzes how crisis periods affected interest in Pillar 3 disclosures, examining changes in interest from 2016 to 2022 using data from a specific bank’s log files. The results, performed through association analysis, indicate a significant decrease in interest in mandatory disclosures during the periods of the COVID-19 pandemic as well as the energy crisis and the war in Ukraine.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| web mining | 10.1007/978-3-031-81596-6_14 | A Review of the Challenges with Massive Web-Mined Corpora Used in Large Language Models Pre-training                | This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain, including challenges such as noise (irrelevant or misleading information), duplication of content, the presence of low-quality or incorrect information, biases, and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate, reliable, and ethically responsible language models. Through an examination of current methodologies for data cleaning, pre-processing, bias detection and mitigation, we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| web mining | 10.1007/s41060-024-00695-7   | Mapping sustainable development goals to citizen science projects–a comparative evaluation of automatic classifiers | Traditional data sources provide insufficient knowledge for measuring the United Nations Sustainable Development Goals (SDGs). Data related to SDGs are sourced primarily from global databases maintained by international organizations, national statistical offices and other government agencies. Recent studies show the value of using data from Citizen Science (CS) for assessing the SDGs. There is an important online presence of CS programs, professional networks for CS and online communities of citizen scientists, leading to the generation of several CS platforms. In this context, the role of computational data science is key. This paper explores and exemplifies opportunities for combining web-data mining techniques and automatic classifiers to enhance the understanding of the inter-relation between CS and the SDGs. An analysis of different automatic classifiers is presented by comparing the results obtained from their application in a sample of 208 CS project descriptions. The results of this study indicate the benefits and limitations of these techniques (nCoder, ESA, OSDG and BERT), but also provides a discussion of the potential benefits of using data from CS projects to map the 17 SDGs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| web mining | 10.1007/s10899-024-10337-z   | Illegal Online Gambling Site Detection using Multiple Resource-Oriented Machine Learning                            | The COVID-19 pandemic has led to faster digitalization and illegal online gambling has become popular. As illegal online gambling brings not only financial threats but also breaches in overall cyber security, this study defines the concept of absolute illegal online gambling (AIOG) using a machine-learning-driven approach with information gathered from public webpages. By analysing 11,172 sites to detect illegal online gambling, the proposed model classifies key features such as URLs (Uniform Resource Locator), WHOIS, INDEX, and landing page information. With a combination of text and image analyses with machine learning-driven approach, the proposed model offers the ensemble combination of attributes for high detection performance with the verification of common attributes from metadata in online gambling. This study suggests a strategy for dynamic resource utilization to increase the classification accuracy of the current environment. As a result, this research expands the scope of hybrid web mining through constant updating of data to achieve content-based filtering.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| web mining | 10.1007/s13132-023-01587-0   | Measuring Innovation in Mauritius’ ICT Sector                                                                       | Measuring innovation accurately and efficiently is crucial for policymakers to encourage innovation activity. However, the established indicator landscape lacks timeliness and accuracy. In this study, we focus on the country of Mauritius that is transforming its economy towards the information and communication technology (ICT) sector. We seek to extend the knowledge base on innovation activity and the status quo of innovation in Mauritius by applying an unsupervised machine learning approach. Building on previous work on new experimental innovation indicators, we combine recent advances in web mining and topic modeling and address the following research questions: What are potential areas of innovation activity in the ICT sector of Mauritius? Furthermore, do web mining and topic modeling provide sufficient indicators to understand innovation activities in emerging countries? To answer these questions, we apply the natural language processing (NLP) technique of Latent Dirichlet Allocation (LDA) to ICT companies’ website text data. We then generate topic models from the scraped text data. As a result, we derive seven categories that describe the innovation activities of ICT firms in Mauritius. Albeit the model approach fulfills the requirements for innovation indicators as suggested in the Oslo Manual, it needs to be combined with additional metrics for innovation, for example, with traditional indicators such as patents, to unfold its potential. Furthermore, our approach carries methodological implications and is intended to be reproduced in similar contexts of scarce or unavailable data or where traditional metrics have demonstrated insufficient explanatory power. |
|            |                              |             Using Unsupervised Machine Learning: A Web Mining and Topic Modeling                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
|            |                              |             Approach                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;web_usage_mining.csv&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| keyword          | doi                          | title                                                                                                                              | abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|:-----------------|:-----------------------------|:-----------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| web usage mining | 10.1007/978-981-96-0476-0_15 | The “Server Access Pattern Analysis” Based on Different “Weblogs Classification” Methods                                           | The academic and industrial sectors have shown a significant increase in interest in web usage mining due to its potential for applications. This work offers a thorough taxonomy of the work being done in this subject, including research projects and the way people use the internet today. During the functioning of the system, extensive information and runtime statistics are recorded in the logs. It includes a log message along with a timestamp that indicates what has taken place in the system. A recent review of the work that has previously performed is also presented, considering various data mining methodologies including clustering and classification. The primary focus of this study is the data preprocessing step, which includes activities such as data cleansing techniques and field extraction at the preliminary stage of ‘web usage mining’. ‘The procedure of ‘extracting’ fields from the log file’s single line is carried out by the field extraction algorithm’. The evaluated data is cleaned by an algorithm that removes items that are incorrect or unnecessary.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| web usage mining | 10.1007/978-981-97-9855-1_33 | Analyze User Navigational Patterns from Log Data Using Hadoop Techniques                                                           | Web usage mining is the process of extracting useful information from web server logs, user interactions, and other web data in order to understand and optimize how users interact with a website. This technique involves analyzing data generated by user activities to discover patterns, trends, and insights that can inform various business and technical decisions. In this research article, we use the Hadoop technique to analyze the behavior of user navigation patterns from log data. This method helps to understand how users interact with websites. For instance, we track the quantity of user logins, the quantity of item sets, the frequency of item sets’ searches, and determine the execution time of various web usage mining algorithms across varying support counts. This article proposes a joint SPM-a priori web mining technique that uses semantic information to improve the generation of frequent sequences and reduces execution time for different support counts. We com-pared existing a priori, web log search, and modified web log search with the proposed join SPM a priori algorithm in Sci-Hub, Pubg game log, Amazon e-commerce, and cryptocurrency datasets. We also found out how long each one took to run for different support counts. The results section says that the proposed SPM-a priori algorithm runs faster than all other algorithms. This means that the proposed system is better for analyzing execution time for user navigational pattern analysis.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| web usage mining | 10.1007/s00799-024-00397-2   | Robots still outnumber humans in web archives in 2019, but less than in 2015 and 2012                                              | The significance of the web and the crucial role of web archives in its preservation highlight the necessity of understanding how users, both human and robot, access web archive content, and how best to satisfy this disparate needs of both types of users. To identify robots and humans in web archives and analyze their respective access patterns, we used the Internet Archive’s (IA) Wayback Machine access logs from 2012, 2015, and 2019, as well as Arquivo.pt’s (Portuguese Web Archive) access logs from 2019. We identified user sessions in the access logs and classified those sessions as human or robot based on their browsing behavior. To better understand how users navigate through the web archives, we evaluated these sessions to discover user access patterns. Based on the two archives and between the three years of IA access logs (2012 vs. 2015 vs. 2019), we present a comparison of detected robots vs. humans and their user access patterns and temporal preferences. The total number of robots detected in IA 2012 (91% of requests) and IA 2015 (88% of requests) is greater than in IA 2019 (70% of requests). Robots account for 98% of requests in Arquivo.pt (2019). We found that the robots are almost entirely limited to “Dip” and “Skim” access patterns in IA 2012 and 2015, but exhibit all the patterns and their combinations in IA 2019. Both humans and robots show a preference for web pages archived in the near past.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| web usage mining | 10.1007/978-981-99-8646-0_16 | Server Access Pattern Analysis Based on Weblogs Classification Methods                                                             | The world of today relies heavily on the internet, online pages, and applications in their daily lives. Web usage mining uses data-mining approaches to extract use patterns from web data in sequence to better comprehend and satisfy Requirements for web-based applications web-based applications. The three phases of web usage mining are pattern identification, pattern analysis, and preprocessing. In-depth explanations of pattern and prediction analysis based on web usage mining are provided in this work. Due to its potential for applications, web usage mining has seen a substantial increase in interest from the academic and industrial sectors. The work in this topic, including research projects and current web usage patterns, is thoroughly taxonomized in this book. Many details and runtime data are captured in logs as the system is operating. A timestamp and a log message that describe what happened in the system are included. The work that has already been done is also reviewed recently, taking into account different data mining approaches including clustering and classification.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| web usage mining | 10.1007/978-981-97-5227-0_31 | Prediction and Analysis of Next Website Requests: A Hybrid Approach Integrating Fuzzy Clustering and Fuzzy Association Rule Mining | Data mining is a vital process for extracting valuable knowledge and intriguing patterns from existing databases, tailored for specific objectives. In the context of web usage mining, the increasing intricacies of web usage necessitate the development of more efficient techniques to predict user behaviour and enhance website performance. Traditional clustering approach ensures that related data points are grouped together while segregating unrelated ones. This study introduces the fuzzy clustering method, which involves categorizing a set of data points into multiple clusters. Fuzzy clustering is employed, allowing data points to possess varying degrees of membership in multiple clusters. Traditional data mining algorithms predominantly rely on binary values to identify transaction relationships. However, real-world applications frequently involve transactions with quantitative values, presenting a substantial challenge in algorithm design. Study presents a pioneering approach that leverages fuzzy clustering algorithms to predict the next website request made by users with a degree of uncertainty and vagueness. This integration of fuzziness results in more precise predictions of user behaviour. Methodologically, study enhances the conventional clustering and association rule mining method by incorporating fuzzy clustering base fuzzy association rule mining method. Paper presents a novel architecture based on fuzzy clustering client based on interest for fuzzy predictions, effectively addressing these challenges.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| web usage mining | 10.1007/s00500-023-08019-w   | IRPDP_HT2: a scalable data pre-processing method in web usage mining using Hadoop MapReduce                                        | Data preparation is a vital step in the web usage mining process since it provides structured data for the subsequent stages. Hence, it is necessary to convert raw server logs into user sessions to generate structured data for pattern discovery phase. In recent decade, popular websites’ server log production has risen to many terabytes to petabytes each day. As a result, server logs possess big data issues such as storage and processing. This study focuses on initial phases of web usage mining process such as data cleaning, user identification, and session identification. These phases are classified as data-intensive processes and deemed-computation intensive. In the last decade, MapReduce emerges as one of the best parallel programming frameworks for data-intensive applications. An efficient MapReduce-based data pre-processing algorithm, i.e. IRPDP_HT2, is proposed in this study. Previous parallel data pre-processing algorithms either include partial phases or lack with efficient robot detection approaches. IRPDP_HT2 algorithm uses a variety of efficient heuristics in all three phases of data pre-processing to identify both ethical and unethical robots. The suggested IRPDP_HT2 approach is found to be effective and scalable for larger datasets after various experiments on a cluster of nodes. The effectiveness of suggested heuristics is also examined during session identification phase. Three variants of IRPDP_HT2 such as PDP_HT2, IPDP_HT2, and RPDP_HT2 are also developed and tested. Impact of robots’ requests and internal dummy connections’ requests on session count by IRPDP_HT2 algorithm is 45.81% which is more than in PDP_HT2, IPDP_HT2, and RPDP_HT2 algorithms. Further speed-up and size-up are also analysed to demonstrate scalability of algorithm. In the presence of larger datasets, the algorithm’s running time falls, while the number of data nodes grows. The size-up of IRPDP_HT2 demonstrates that even after doubling the input data, the algorithm’s running time does not grow in that ratio for the fixed number of data nodes. |
| web usage mining | 10.1007/978-981-99-4284-8_3  | Multi-criteria-Based Page Ranking Using Metaheuristic Swarm Optimization                                                           | The size of data on the internet has grown enormously and also growing continuously. Finding any information for a user in response to query has become a challenging task. In this, search engines are playing a vital role. Yet, these are unable to a retrieve the relevant information. These search engines use some limited criteria to fetch the results in response to the user&#39;s query after ranking and indexing the pages. In this paper, a multi-criteria-based approach has been proposed to rank web pages. These criteria include keywords, user access count, unique visitors, stay time, hubs, and authority values. The proposed approach uses particle swarm optimization to find the optimal results. And, this algorithm has been compared with some existing algorithms based on iterative improvement and genetic algorithm. It has been observed that the proposed approach is able to find the most relevant top-ranked pages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| web usage mining | 10.1007/978-3-031-29078-7_60 | Website Personalization Using Association Rules Mining                                                                             | Many companies are redefining their business strategies to improve the business output. Business over internet provides the opportunity to customers and partners where their products and specific business can be found. Web usage mining is the type of web mining activity that involves the automatic discovery of user access patterns from web servers. A real-world challenging task of the web master of an organization is to match the needs of user and keep their attention in their web site. So, web pages can capture the intuition of the user and provide them with the recommendation list. Personalize e-commerce website is done after knowing the habits and behavior patterns of customers e-commerce website using web usage mining with association rules mining apriori algorithms. The method used is a method of analysis and design. In the method of analysis, research variables are determined, and data of sales are collected. In addition, the method of analysis is also performed to measure the accuracy of the apriori algorithm. Designing apriori, program design, and the design of the screen is done in the design method. Results are achieved in the form of an e-commerce website that is personalized using association rules mining apriori algorithm that can recommend the goods in accordance with the preferences and needs of the user. The conclusion of this study is to obtain patterns of association, it takes the data transactions made by customers and the recommendations given by the apriori algorithm would be more accurate if the transaction data is processed more, the categories of goods are fewer, the limit minimum value of support and the limit minimum value of confidence are high.                                                                                                                                                                                                                                                                                                                                                                          |
| web usage mining | 10.1007/978-981-99-7969-1_7  | Web Usage Mining for Determining a Website’s Usage Pattern: A Case Study of Government Website                                     | Web usage mining is a crucial research area that aims to uncover user behavior patterns from web log data because web usage mining can be used to analyze a website’s usage. This study examined web usage mining to discover online users’ usage patterns and used the results to redesign and improve the government website. This study aims to help online customers obtain a better experience. A dataset was collected from the Metropolitan Electricity Authority (MEA) website. Various algorithms, including association rule mining (Apriori and Frequent Pattern-Growth (FP-Growth)) and sequential pattern mining (Generalized Sequential Pattern (GSP) and Prefix-Span), were used to mine the user usage data. The first 30 frequently visited patterns of web usage mining results were selected for analysis and to develop a prototype. It revealed that most pages were accessed directly. Moreover, most users were interested in alternative energy information, the Fuel Adjustment Charge (at the given time) or the FT rate, the power outage announcement page, and reducing electric expenses information. Furthermore, the analysis indicated that customers were interested in making online processes, such as using the contact-us feature, downloading forms, and calculating their electric expenses. A survey was conducted with 30 participants and the results were compared with the usage data from the weblog. Welch’s t-test was utilized to evaluate the prototype. The findings indicated that the newly implemented website, based on the user usage patterns, was more effective and reduced the user’s usage time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| web usage mining | 10.1007/978-3-031-16802-4_19 | Robots Still Outnumber Humans in Web Archives, But Less Than Before                                                                | To identify robots and humans and analyze their respective access patterns, we used the Internet Archive’s (IA) Wayback Machine access logs from 2012 and 2019, as well as Arquivo.pt’s (Portuguese Web Archive) access logs from 2019. We identified user sessions in the access logs and classified those sessions as human or robot based on their browsing behavior. To better understand how users navigate through the web archives, we evaluated these sessions to discover user access patterns. Based on the two archives and between the two years of IA access logs (2012 vs. 2019), we present a comparison of detected robots vs. humans and their user access patterns and temporal preferences. The total number of robots detected in IA 2012 is greater than in IA 2019 (21% more in requests and 18% more in sessions). Robots account for 98% of requests (97% of sessions) in Arquivo.pt (2019). We found that the robots are almost entirely limited to “Dip” and “Skim” access patterns in IA 2012, but exhibit all the patterns and their combinations in IA 2019. Both humans and robots show a preference for web pages archived in the near past.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Tugas.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Pengantar Web Mining</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-library-sprynger">1. Install Library Sprynger</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-api-key">2. Menyiapkan API Key</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#script-crawling-python">3. Script Crawling Python</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-keyword-web-mining">A. Keyword Web Mining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-keyword-web-usage-mining">B. Keyword Web Usage Mining</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
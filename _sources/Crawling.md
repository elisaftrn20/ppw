# Crawling Data

Proses untuk Crawling data yaitu, 

## 1. Install Library Sprynger

Untuk memasang library Python resmi Springer Nature, jalankan:

```{bash}
!pip install sprynger
```

## 2. Menyiapkan API Key
Setiap pencarian membutuhkan API Key dari Springer Nature agar kita diizinkan mengambil data.
Daftar di Springer Nature Developer di https://dev.springernature.com/#api

## 3. Script Crawling Python

Setelah mendapatkan api key dari Springer Nature Developer, masukkan API yang telah didapat ke dalam code dibawah ini, dan saya mengimplementasikannya dengan menggunakan keyword web mining

### A. Keyword Web Mining 

```python
import requests
import pandas as pd

# API Key Meta API
api_key = "00e6e834d8efc1827d4b56d5091e03b1"
keyword = "web mining"

url = "https://api.springernature.com/meta/v2/json"
params = {
    "q": f'keyword:"{keyword}"',
    "api_key": api_key,
    "p": 10  # jumlah hasil per request
}

response = requests.get(url, params=params)

# List untuk menyimpan semua record
all_records = []

if response.status_code == 200:
    data = response.json()
    total_results = data['result'][0].get('total', 0)
    print(f"Total hasil: {total_results}\n")
    
    for record in data.get("records", []):
        doi = record.get('doi', 'N/A')
        title = record.get('title', 'No title')
        abstract = record.get('abstract', 'No abstract')
        print(f"DOI: {doi}")
        print(f"Title: {title}")
        print(f"Abstract: {abstract}\n")
        
        # Simpan record ke list
        all_records.append({
            "keyword": keyword,
            "doi": doi,
            "title": title,
            "abstract": abstract
        })
else:
    print("Error:", response.status_code, response.text)

# Simpan ke CSV
if all_records:
    df = pd.DataFrame(all_records)
    csv_filename = f"{keyword.replace(' ', '_')}.csv"  # hasil: web_mining.csv
    df.to_csv(csv_filename, index=False, encoding="utf-8")
    print(f"✅ Data berhasil disimpan ke {csv_filename}")

```
Hasil yang didapatkan adalah 
 keyword    | doi                          | title                                                                                                               | abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|:-----------|:-----------------------------|:--------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| web mining | 10.1007/s41060-023-00483-9   | Artificial intelligence trend analysis in German business and politics: a web mining approach                       | Current research on trend detection in artificial intelligence (AI) mainly concerns academic data sources and industrial applications of AI. However, we argue that industrial trends are influenced by public perception and political decisions (e.g., through industry subsidies and grants) and should be reflected in political data sources. To investigate this hypothesis, we examine the AI trend development in German business and politics from 1998 to 2020. Therefore, we propose a web mining approach to collect a novel data set consisting of business and political data sources combining 1.07 million articles and documents. We identify 246 AI-related buzzwords extracted from various glossaries. We use them to conduct an extensive trend detection and analysis study on the collected data using machine learning-based approaches. This study successfully detects an AI trend and follows its evolution in business and political data sources over the past two decades. Moreover, we find a faster adoption of AI in business than in politics, with a considerable increase in policy discourse in recent years. Finally, we show that the collected data can be used for trend detection besides AI-related topics using topic clustering and the COVID-19 pandemic as examples.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| web mining | 10.1007/s11135-024-01978-8   | Information diffusion in referral networks: an empirical investigation of the crypto asset landscape                | In the last decades, crypto assets have become particularly popular in financial markets. However, public awareness of the crypto asset landscape is rather limited, and usually associated with sensationalized media coverage of a handful of cryptocurrencies. Moreover, while users of crypto assets primarily collect information on Internet, there is a limited understanding of the relational (online) structures supporting the diffusion of information about these financial products. Therefore, the aim of this study is to uncover the structure of online information referral networks dedicated to crypto assets. By adopting a multi-method approach consisting of web scraping, web analytics, and social network analysis, we use data from the top 200 crypto assets by market capitalization to identify pivotal websites and the overall connectedness of the information referral networks. Our results show that social media and news channel sites play a key role in the information diffusion process, while market and trading sites signal innovation adoption. Overall, cryptocurrencies’ websites do not seem key in the referral network, as opposed to social media websites which, however, cannot be considered mature hubs because of their low connectivity.                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| web mining | 10.1007/978-3-031-73699-5_16 | NoCrypto: A Web Mining Behavior Detection Method Based on RGB Images                                                | In recent years, there has been a growing prevalence of mining web pages using the new web technology of WebAssembly (WASM), resulting in the unauthorized exploitation of user resources. However, existing detection methods have shown limited ability to counter obfuscation techniques and have exhibited low detection efficiency. To address these issues, this paper proposes a novel static detection method based on the visualization of WASM modules. The proposed method involves instantiating the binary files of the WASM mining operations within web pages. These binary files are then combined with the information of local entropy and global entropy, resulting in the visualization of RGB images. Compared to grayscale images, RGB images retain more of the original file information. After training and learning the image features using a convolutional neural network (CNN), the model achieves an impressive accuracy rate of 99.18% when tested on real-world web pages. This accuracy is approximately 2% higher than that of existing visualization-based detection methods. Moreover, the model exhibits a shorter execution time. The proposed NoCrypto method demonstrates quick execution speed and accurate detection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| web mining | 10.1007/978-3-031-85386-9_9  | On Understanding the Dark Web Through Graph Analytics                                                               | The Dark Web, a protected digital graph, contains a wealth of hidden information that evades traditional search engines. This work delves into the mysterious landscape of the Dark Web by analyzing its structure using graph data from a Dark Web crawler. Using exploratory data analysis techniques, we uncover structure, trends, and insights that contribute to a deeper understanding of the content hidden in this dark digital world. This research is a critical step toward understanding the contents of the Dark Web and improving our ability to navigate the complexities of the digital underworld.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| web mining | 10.1007/978-3-031-86302-8_5  | A Survey on Various Sentiment Analysis Applications Employing Opinion Mining                                        | Opinion mining aka sentiment analysis refers to the use of natural language processing, text analysis and computational linguistics to identify and extract subjective information in source data. This, further helps to extract the subjective information into various categories that help in a decision-making process. In this survey, a novel attempt is made to provide an application-specific classification on opinion mining and sentiment analysis. The survey presented here widely covers the processes, levels and challenges of opinion mining that would help the application designers of opinion mining applications.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| web mining | 10.1007/978-3-031-81261-3_9  | Pillar 3: Did COVID-19 and the War in Ukraine Affect Interest in Mandatory Disclosure?                              | The 2008–2009 financial crisis exposed significant flaws in the Basel II regulatory framework, which was designed to ensure the stability of banking institutions during crises. This economic turmoil led to a loss of confidence in financial systems, liquidity shortages, and a deepening debt crisis across Europe. In response, regulatory standards were reformed, resulting in the development of the Basel III framework, which built upon three pillars. Pillar 1 introduced better capital forms, higher capital ratios, and capital reserves. Pillar 2 increased risk management requirements and emphasized the supervisory authorities’ responsibilities. Pillar 3 enhanced the scope and detail of published information, aiming to improve market discipline and stakeholder understanding of banks’ risks and capital positions. Our study analyzes how crisis periods affected interest in Pillar 3 disclosures, examining changes in interest from 2016 to 2022 using data from a specific bank’s log files. The results, performed through association analysis, indicate a significant decrease in interest in mandatory disclosures during the periods of the COVID-19 pandemic as well as the energy crisis and the war in Ukraine.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| web mining | 10.1007/978-3-031-81596-6_14 | A Review of the Challenges with Massive Web-Mined Corpora Used in Large Language Models Pre-training                | This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain, including challenges such as noise (irrelevant or misleading information), duplication of content, the presence of low-quality or incorrect information, biases, and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate, reliable, and ethically responsible language models. Through an examination of current methodologies for data cleaning, pre-processing, bias detection and mitigation, we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| web mining | 10.1007/s41060-024-00695-7   | Mapping sustainable development goals to citizen science projects–a comparative evaluation of automatic classifiers | Traditional data sources provide insufficient knowledge for measuring the United Nations Sustainable Development Goals (SDGs). Data related to SDGs are sourced primarily from global databases maintained by international organizations, national statistical offices and other government agencies. Recent studies show the value of using data from Citizen Science (CS) for assessing the SDGs. There is an important online presence of CS programs, professional networks for CS and online communities of citizen scientists, leading to the generation of several CS platforms. In this context, the role of computational data science is key. This paper explores and exemplifies opportunities for combining web-data mining techniques and automatic classifiers to enhance the understanding of the inter-relation between CS and the SDGs. An analysis of different automatic classifiers is presented by comparing the results obtained from their application in a sample of 208 CS project descriptions. The results of this study indicate the benefits and limitations of these techniques (nCoder, ESA, OSDG and BERT), but also provides a discussion of the potential benefits of using data from CS projects to map the 17 SDGs.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| web mining | 10.1007/s10899-024-10337-z   | Illegal Online Gambling Site Detection using Multiple Resource-Oriented Machine Learning                            | The COVID-19 pandemic has led to faster digitalization and illegal online gambling has become popular. As illegal online gambling brings not only financial threats but also breaches in overall cyber security, this study defines the concept of absolute illegal online gambling (AIOG) using a machine-learning-driven approach with information gathered from public webpages. By analysing 11,172 sites to detect illegal online gambling, the proposed model classifies key features such as URLs (Uniform Resource Locator), WHOIS, INDEX, and landing page information. With a combination of text and image analyses with machine learning-driven approach, the proposed model offers the ensemble combination of attributes for high detection performance with the verification of common attributes from metadata in online gambling. This study suggests a strategy for dynamic resource utilization to increase the classification accuracy of the current environment. As a result, this research expands the scope of hybrid web mining through constant updating of data to achieve content-based filtering.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| web mining | 10.1007/s13132-023-01587-0   | Measuring Innovation in Mauritius’ ICT Sector                                                                       | Measuring innovation accurately and efficiently is crucial for policymakers to encourage innovation activity. However, the established indicator landscape lacks timeliness and accuracy. In this study, we focus on the country of Mauritius that is transforming its economy towards the information and communication technology (ICT) sector. We seek to extend the knowledge base on innovation activity and the status quo of innovation in Mauritius by applying an unsupervised machine learning approach. Building on previous work on new experimental innovation indicators, we combine recent advances in web mining and topic modeling and address the following research questions: What are potential areas of innovation activity in the ICT sector of Mauritius? Furthermore, do web mining and topic modeling provide sufficient indicators to understand innovation activities in emerging countries? To answer these questions, we apply the natural language processing (NLP) technique of Latent Dirichlet Allocation (LDA) to ICT companies’ website text data. We then generate topic models from the scraped text data. As a result, we derive seven categories that describe the innovation activities of ICT firms in Mauritius. Albeit the model approach fulfills the requirements for innovation indicators as suggested in the Oslo Manual, it needs to be combined with additional metrics for innovation, for example, with traditional indicators such as patents, to unfold its potential. Furthermore, our approach carries methodological implications and is intended to be reproduced in similar contexts of scarce or unavailable data or where traditional metrics have demonstrated insufficient explanatory power. |
|            |                              |             Using Unsupervised Machine Learning: A Web Mining and Topic Modeling                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
|            |                              |             Approach                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |


### B. Keyword Web Usage Mining 

``` python
import requests
import pandas as pd

# API Key Meta API
api_key = "00e6e834d8efc1827d4b56d5091e03b1"
keyword = "web usage mining"

url = "https://api.springernature.com/meta/v2/json"
params = {
    "q": f'keyword:"{keyword}"',
    "api_key": api_key,
    "p": 10  # jumlah hasil per request
}

response = requests.get(url, params=params)

# List untuk menyimpan semua record
all_records = []

if response.status_code == 200:
    data = response.json()
    total_results = data['result'][0].get('total', 0)
    print(f"Total hasil: {total_results}\n")
    
    for record in data.get("records", []):
        doi = record.get('doi', 'N/A')
        title = record.get('title', 'No title')
        abstract = record.get('abstract', 'No abstract')
        print(f"DOI: {doi}")
        print(f"Title: {title}")
        print(f"Abstract: {abstract}\n")
        
        # Simpan record ke list
        all_records.append({
            "keyword": keyword,
            "doi": doi,
            "title": title,
            "abstract": abstract
        })
else:
    print("Error:", response.status_code, response.text)

# Simpan ke CSV
if all_records:
    df = pd.DataFrame(all_records)
    csv_filename = f"{keyword.replace(' ', '_')}.csv"  # keyword_web_mining.csv
    df.to_csv(csv_filename, index=False, encoding="utf-8")
    print(f"\n✅ Data berhasil disimpan ke {csv_filename}")

```
